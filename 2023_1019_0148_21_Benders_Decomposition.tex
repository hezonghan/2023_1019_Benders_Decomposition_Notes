
\documentclass[twocolumn]{ctexart}
% \documentclass[onecolumn]{ctexart}

\usepackage{geometry}
\geometry{a4paper,left=1cm,right=1cm,top=1.4cm,bottom=1cm}

\usepackage{amsmath,amssymb,amsfonts}
\usepackage{xcolor}
\usepackage{graphicx}  % for \resizebox
\usepackage{arydshln}



\usepackage{hyperref}
\hypersetup{
    pdfstartview={XYZ null null 1.25},  % XYZ <left> <top> <zoom> : Sets a coordinate and a zoom factor. If anyone is null, the source link value is used.
    % pdfstartview={FitH  null},           % FitH <top> : fit the width of the page to the window
    pdfpagelayout=OneColumn,  % SinglePage/OneColumn/...
    % 
    bookmarks=true,
    bookmarksnumbered=true,
    bookmarksopen=true,  % whether bookmark tree is expanded when opening pdf
    pdfpagemode=UseOutlines,  % UseOutlines: show bookmarks panel when opening pdf
    % 
    linkbordercolor=blue,
}



\begin{document}

\leftline{2023\_1019\_0148\_21}





% IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
\vspace{30pt}
\section{Preliminaries}

% =================================================================
% \iffalse
\subsection{Standard Form of LP}

Any unbounded variable $x$ can be replaced by a pair of non-negative variables $(u,v)$.
\begin{equation}
    \begin{aligned}
        \label{eq:var_unbounded_to_nonnegative}
        \begin{cases}
            x = u - v \\
            u \geq 0  \\
            v \geq 0  \\
        \end{cases}
    \end{aligned}
\end{equation}

Any in-equality constraint can be converted into an equality constraint,
by introducing an additional assistant non-negative variable $x'$.
\begin{equation}
    \begin{aligned}
        \label{eq:cons_inequal_to_equal}
        \mathbf{a}_i^T  \mathbf{x}  \geq  b_i
        & \qquad \Leftrightarrow \qquad
        \begin{cases}
            \mathbf{a}_i^T \mathbf{x}  -  x'  &=  b_i \\
            x' &\geq 0 \\
        \end{cases}
        \\
        & \qquad \Leftrightarrow \qquad
        \begin{cases}
            \begin{bmatrix} \mathbf{a}_i^T &  (-1) \end{bmatrix}
            \begin{bmatrix} \mathbf{x}     \\ x' \end{bmatrix}
            &= b_i
            \\
            x' &\geq 0 \\
        \end{cases}
    \end{aligned}
\end{equation}

So we can safely represent any Linear Programming (LP) problem in its standard form,
with only non-negative variables and only equality constraints.
% \fi





% \subsection{What about LPs in standard form}
% ----------------------------
\subsubsection{Example}
% \subsubsection{Example 1:}

The LP with equalities and in-equalities
\begin{equation}
    \begin{aligned}
        \label{eq:mixed_equal_and_inequal}
        \text{Minimize} \qquad &
            \mathbf{c}^T  \mathbf{\color{red} x}
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                \mathbf{A}^{(e)}  \mathbf{\color{red} x}  &  =     \mathbf{b}^{(e)}  {\color{gray} \quad \in \mathbb{R}^{m^{(e)} \times 1}}  \\
                \mathbf{A}^{(i)}  \mathbf{\color{red} x}  &  \geq  \mathbf{b}^{(i)}  {\color{gray} \quad \in \mathbb{R}^{m^{(i)} \times 1}}  \\
                                  \mathbf{\color{red} x}  &  \geq  \mathbf{0}        {\color{gray} \quad \in \mathbb{R}^{n \times 1}}  \\
            \end{cases}
    \end{aligned}
\end{equation}
% can be transformed to elininate in-equalities
can be transformed to a standard form without in-equalities
\begin{equation}
    \begin{aligned}
        \label{eq:only_equal}
        \text{Minimize} \qquad &
            \mathbf{c}^T  \mathbf{\color{red} x}
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                \mathbf{A}^{(e)}  \mathbf{\color{red} x}                 &  =     \mathbf{b}^{(e)}  {\color{gray} \quad \in \mathbb{R}^{m^{(e)} \times 1}}  \\
                \mathbf{A}^{(i)}  \mathbf{\color{red} x}  -  \mathbf{y}  &  =     \mathbf{b}^{(i)}  {\color{gray} \quad \in \mathbb{R}^{m^{(i)} \times 1}}  \\
                                  \mathbf{\color{red} x}                 &  \geq  \mathbf{0}        {\color{gray} \quad \in \mathbb{R}^{n       \times 1}}  \\
                                  \mathbf{\color{red} y}                 &  \geq  \mathbf{0}        {\color{gray} \quad \in \mathbb{R}^{m^{(i)} \times 1}}  \\
            \end{cases}
    \end{aligned}
\end{equation}




% =================================================================
% \iffalse
\subsection{In-equality Form of LP}

Conversely,
any equality constraint can also be converted into in-equality constraints,
by using a pair of "opposite" constraints.

\begin{equation}
    \begin{aligned}
        \label{eq:cons_equal_to_inequal}
        \mathbf{a}_i^T  \mathbf{x}  =  b_i
        & \qquad \Leftrightarrow \qquad
        \begin{cases}
            \mathbf{a}_i^T \mathbf{x}  \geq  b_i \\
            \mathbf{a}_i^T \mathbf{x}  \leq  b_i \\
        \end{cases}
        \\
        & \qquad \Leftrightarrow \qquad
        \begin{cases}
            +\mathbf{a}_i^T \mathbf{x}  \geq  +b_i \\
            -\mathbf{a}_i^T \mathbf{x}  \geq  -b_i \\
        \end{cases}
        \\
        & \qquad \Leftrightarrow \qquad
        \begin{cases}
            \begin{bmatrix}  \mathbf{a}_i^T  \\  -\mathbf{a}_i^T  \end{bmatrix}
            \mathbf{x}
            &\geq
            \begin{bmatrix}  +b_i  \\  -b_i  \end{bmatrix}
        \end{cases}
    \end{aligned}
\end{equation}



% ----------------------------
\subsubsection{Example}

The LP with equalities and in-equalities Eq.(\ref{eq:mixed_equal_and_inequal})
can also be transformed to an in-equality form without equalities
\begin{equation}
    \begin{aligned}
        \label{eq:only_inequal}
        \text{Minimize} \qquad &
            \mathbf{c}^T  \mathbf{\color{red} x}
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                +\mathbf{A}^{(e)}  \mathbf{\color{red} x}  &  \geq  +\mathbf{b}^{(e)}  {\color{gray} \quad \in \mathbb{R}^{m^{(e)} \times 1}}  \\
                -\mathbf{A}^{(e)}  \mathbf{\color{red} x}  &  \geq  -\mathbf{b}^{(e)}  {\color{gray} \quad \in \mathbb{R}^{m^{(e)} \times 1}}  \\
                 \mathbf{A}^{(i)}  \mathbf{\color{red} x}  &  \geq   \mathbf{b}^{(i)}  {\color{gray} \quad \in \mathbb{R}^{m^{(i)} \times 1}}  \\
                                   \mathbf{\color{red} x}  &  \geq   \mathbf{0}        {\color{gray} \quad \in \mathbb{R}^{n       \times 1}}  \\
            \end{cases}
    \end{aligned}
\end{equation}










% IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
\clearpage
\vspace{30pt}
\section{LP and Duality}

% =================================================================
\subsection{Definition of Dual}
\label{sec:def_of_dual}

Assume
$\mathbf{A} \in \mathbb{R}^{m \times n}$
,
$\mathbf{b} \in \mathbb{R}^{m \times 1}$
,
$\mathbf{c} \in \mathbb{R}^{n \times 1}$
.
% A LP problem
The LP problem \textbf{\color{blue} (in in-equality form)}
\begin{equation}
    \begin{aligned}
        \label{eq:primal}
        \text{Minimize} \qquad &
            \mathbf{c}^T  \mathbf{\color{red} x}
        \\
        \text{s.t.} \qquad &
            % &  A  \mathbf{x}  &  \geq  \mathbf{b}  \\
            % &     \mathbf{x}  &   \geq  \mathbf{0}  \\
            \begin{cases}
                \mathbf{A}  \mathbf{\color{red} x}  &  \geq  \mathbf{b}  {\color{gray} \quad \in \mathbb{R}^{m \times 1}}  \\
                            \mathbf{\color{red} x}  &  \geq  \mathbf{0}  {\color{gray} \quad \in \mathbb{R}^{n \times 1}}  \\
            \end{cases}
    \end{aligned}
\end{equation}
has a dual problem defined as
\begin{equation}
    \begin{aligned}
        \label{eq:dual}
        \text{Maximize} \qquad &
            \mathbf{b}^T  \mathbf{\color{red} \lambda}
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                \mathbf{A}^T  \mathbf{\color{red} \lambda}  &  \leq  \mathbf{c}  {\color{gray} \quad \in \mathbb{R}^{n \times 1}}  \\
                              \mathbf{\color{red} \lambda}  &  \geq  \mathbf{0}  {\color{gray} \quad \in \mathbb{R}^{m \times 1}}  \\
            \end{cases}
    \end{aligned}
\end{equation}
% and note that,
and we can conclude that the dual derivation process is simple:
\begin{itemize}
    \item  ($\mathbf{A} \Leftrightarrow \mathbf{A}^T$) coefficient matrix is transposed
    \item  ($\mathbf{b} \Leftrightarrow \mathbf{c}$) cost and constraint vectors are interchanged
    \item  ($\leq \  \Leftrightarrow \  \geq$) constraint in-equalities are reversed
    \item  (maximizing $\Leftrightarrow$ minimizing) optimization direction is reversed
\end{itemize}
and also note that the sizes/lengths of matrices/vectors are changed accordingly.


\vspace{40pt}


Following this definition,
the LP problem \textbf{\color{blue} (in standard form)}
\begin{equation}
    \begin{aligned}
        \label{eq:primal_standard}
        \text{Minimize} \qquad &
            \mathbf{c}^T  \mathbf{\color{red} x}
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                \mathbf{A}  \mathbf{\color{red} x}  &  =     \mathbf{b}  {\color{gray} \quad \in \mathbb{R}^{m \times 1}}  \\
                            \mathbf{\color{red} x}  &  \geq  \mathbf{0}  {\color{gray} \quad \in \mathbb{R}^{n \times 1}}  \\
            \end{cases}
    \end{aligned}
\end{equation}
which can be converted into in-equality form as
\begin{equation}
    \begin{aligned}
        \label{eq:primal_standard_converted}
        \text{Minimize} \qquad &
            \mathbf{c}^T  \mathbf{\color{red} x}
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                % +\mathbf{A}  \mathbf{\color{red} x}  &  \geq  +\mathbf{b}  {\color{gray} \quad \in \mathbb{R}^{m \times 1}}  \\
                % -\mathbf{A}  \mathbf{\color{red} x}  &  \geq  -\mathbf{b}  {\color{gray} \quad \in \mathbb{R}^{m \times 1}}  \\
                \begin{bmatrix}  +\mathbf{A}  \\  -\mathbf{A} \end{bmatrix}
                \mathbf{\color{red} x}
                &  \geq
                \begin{bmatrix}  +\mathbf{b}  \\  -\mathbf{b} \end{bmatrix}
                {\color{gray} \quad \in \mathbb{R}^{(2m) \times 1}}  \\
                             \mathbf{\color{red} x}  &  \geq   \mathbf{0}  {\color{gray} \quad \in \mathbb{R}^{n \times 1}}  \\
            \end{cases}
    \end{aligned}
\end{equation}
should have a dual problem as
\begin{equation}
    \begin{aligned}
        \label{eq:primal_standard_dual}
        \text{Maximize} \qquad &
            \begin{bmatrix}  +\mathbf{b}^T  &  -\mathbf{b}^T \end{bmatrix}
            \mathbf{\color{red} \lambda}
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                \begin{bmatrix}  +\mathbf{A}^T  &  -\mathbf{A}^T \end{bmatrix}
                \mathbf{\color{red} \lambda}  &  \leq  \mathbf{c}  {\color{gray} \quad \in \mathbb{R}^{n \times 1}}  \\
                \mathbf{\color{red} \lambda}  &  \geq  \mathbf{0}  {\color{gray} \quad \in \mathbb{R}^{(2m) \times 1}}  \\
            \end{cases}
    \end{aligned}
\end{equation}
Partitioning $\mathbf{\lambda} {\color{gray} \in \mathbb{R}^{(2m) \times 1}}$
as $\begin{bmatrix}  \mathbf{\lambda}_1  {\color{gray} \quad \in \mathbb{R}^{m \times 1}}  \\  \mathbf{\lambda}_2  {\color{gray} \quad \in \mathbb{R}^{m \times 1}} \end{bmatrix}$
and we have
\begin{equation}
    \begin{aligned}
        \label{eq:primal_standard_dual_partitioned}
        \text{Maximize} \qquad &
            % +\mathbf{b}^T
            % % \mathbf{\color{red} \lambda_1}
            % {\color{red} \mathbf{\lambda}_1}
            % -\mathbf{b}^T
            % % \mathbf{\color{red} \lambda_2}
            % {\color{red} \mathbf{\lambda}_2}
            % =
            \mathbf{b}^T
            % (\mathbf{\color{red} \lambda_1} - \mathbf{\color{red} \lambda_2})
            ({\color{red} \mathbf{\lambda}_1} - {\color{red} \mathbf{\lambda}_2})
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                % +\mathbf{A}^T
                % % \mathbf{\color{red} \lambda_1}
                % {\color{red} \mathbf{\lambda}_1}
                % -\mathbf{A}^T
                % % \mathbf{\color{red} \lambda_2}
                % {\color{red} \mathbf{\lambda}_2}
                % =
                \mathbf{A}^T
                % (\mathbf{\color{red} \lambda_1} - \mathbf{\color{red} \lambda_2})
                ({\color{red} \mathbf{\lambda}_1} - {\color{red} \mathbf{\lambda}_2})
                &  \leq  \mathbf{c}  {\color{gray} \quad \in \mathbb{R}^{n \times 1}}
                \\
                {\color{red} \mathbf{\lambda}_1}  &  \geq  \mathbf{0}  {\color{gray} \quad \in \mathbb{R}^{(m) \times 1}}
                \\
                {\color{red} \mathbf{\lambda}_2}  &  \geq  \mathbf{0}  {\color{gray} \quad \in \mathbb{R}^{(m) \times 1}}
                \\
            \end{cases}
    \end{aligned}
\end{equation}
and we can safely combine the free non-negative variables pairs $\mathbf{\lambda}' = (\mathbf{\lambda}_1 - \mathbf{\lambda}_2)$, resulting in
\begin{equation}
    \begin{aligned}
        \label{eq:primal_standard_dual_partitioned_combined}
        \text{Maximize} \qquad &
            \mathbf{b}^T
            % \mathbf{\color{red} \lambda'}
            {\color{red} \mathbf{\lambda}'}
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                \mathbf{A}^T
                {\color{red} \mathbf{\lambda}'}
                &  \leq  \mathbf{c}  {\color{gray} \quad \in \mathbb{R}^{n \times 1}}
                \\
                {\color{red} \mathbf{\lambda}'}  &  \geq  -\mathbf{\infty}  {\color{gray} \quad \in \mathbb{R}^{m \times 1}}
                \\
                & \text{\color{red}  (variables not necessarily non-negative)}
                \\
            \end{cases}
    \end{aligned}
\end{equation}





% =================================================================
\subsection{The Duality Theorem}

So what is the relationship between Eq.(\ref{eq:primal}) and its dual Eq.(\ref{eq:dual}) defined in section \ref{sec:def_of_dual} ?

We will explore
% based on the pair of dual
, based on the dual of standard form,
Eq.(\ref{eq:primal_standard}) and Eq.(\ref{eq:primal_standard_dual_partitioned_combined}).


% ----------------------------
\subsubsection{Weak Duality Lemma}

% If
% $\mathbf{x}$ is feasible in Eq.(\ref{eq:primal_standard})
% and
% $\mathbf{\lambda}'$ is feasible in Eq.(\ref{eq:primal_standard_dual_partitioned_combined}),

If
Eq.(\ref{eq:primal_standard})
and
Eq.(\ref{eq:primal_standard_dual_partitioned_combined})
are both feasible,
then
any feasible solution $\mathbf{x}$        for Eq.(\ref{eq:primal_standard})
as well as
any feasible solution $\mathbf{\lambda}'$ for Eq.(\ref{eq:primal_standard_dual_partitioned_combined})
satisfies:


\begin{equation}
    \begin{aligned}
        \label{eq:weak_duality_lemma}
        &
        \mathbf{b}^T
        {\color{red} \mathbf{\lambda}'}
        % =&
        % {\color{red} \mathbf{\lambda}'{}^T}
        % \mathbf{b}
        % \\=&
        % {\color{red} \mathbf{\lambda}'{}^T}
        % \mathbf{A}
        % {\color{red} \mathbf{x}}
        \\=&
        (
            \mathbf{A}
            {\color{red} \mathbf{x}}
        )^T
        {\color{red} \mathbf{\lambda}'}
        % \qquad \text{\color{gray} by constraints in Eq.(\ref{eq:primal_standard})}
        \qquad {\color{gray} \text{by} \quad
            \mathbf{A}  \mathbf{x}  =  \mathbf{b}  \quad \text{in Eq.(\ref{eq:primal_standard})}
        }
        \\=&
        {\color{red} \mathbf{x}^T}
        (
            \mathbf{A}^T
            {\color{red} \mathbf{\lambda}'}
        )
        \\ \leq &
        {\color{red} \mathbf{x}^T}
        \mathbf{c}
        % \qquad \text{\color{gray} by constraints in Eq.(\ref{eq:primal_standard_dual_partitioned_combined})}
        \qquad {\color{gray} \text{by} \quad
            \begin{cases}
                \mathbf{A}^T  \mathbf{\lambda}'  \leq  \mathbf{c}  \quad \text{in Eq.(\ref{eq:primal_standard_dual_partitioned_combined})}
                \\
                \mathbf{x} \geq \mathbf{0}                         \quad \text{in Eq.(\ref{eq:primal_standard})}
            \end{cases}
        }
        \\=&
        \mathbf{c}^T
        {\color{red} \mathbf{x}}
    \end{aligned}
\end{equation}
% meaning that the objectives of a pair of feasible solutions
meaning that,
\begin{itemize}
    \item
    the objective of \textbf{any feasible} solution of a standard form LP as Eq.(\ref{eq:primal_standard})
    should always be larger than or equal to
    the objective of \textbf{any feasible} solution of its dual as Eq.(\ref{eq:primal_standard_dual_partitioned_combined}).
\end{itemize}
and therefore,
\begin{itemize}
    \item
    If either problem has an unbounded optimal objective,
    the other problem will be in-feasible.
    \item
    If both Eq.(\ref{eq:primal_standard}) and Eq.(\ref{eq:primal_standard_dual_partitioned_combined}) are feasible,
    the objective of \textbf{the optimal} solution of a standard form LP as Eq.(\ref{eq:primal_standard})
    should always be larger than or equal to
    the objective of \textbf{the optimal} solution of its dual as Eq.(\ref{eq:primal_standard_dual_partitioned_combined}).
    % (Note that Eq.(\ref{eq:primal_standard}) seeks for minimum, and Eq.(\ref{eq:primal_standard_dual_partitioned_combined}) seeks for maximum.)
    \begin{itemize}
        \item
        If we come across a pair of feasible solutions $(\mathbf{x}, \mathbf{\lambda}')$ where the equality holds,
        then they should be (one of) the corresponding optimal solutions of each problem.
    \end{itemize}
\end{itemize}
(Note that Eq.(\ref{eq:primal_standard}) seeks for minimum, and Eq.(\ref{eq:primal_standard_dual_partitioned_combined}) seeks for maximum.)



% ----------------------------
\subsubsection{Strong Duality Theorem}

% But, whether we can achieve this equality?
% But, can we (always) achieve this equality in Eq.(\ref{eq:weak_duality_lemma})?
However,
the above comparison is weak, and
these questions currently remain:
\begin{itemize}
    \item
    If either problem is in-feasible,
    should the other problem have an unbounded optimal objective?
    \item
    If either problem has a finite optimal objective,
    should the other problem also have a finite optimal objective?
    \item
    If both Eq.(\ref{eq:primal_standard}) and Eq.(\ref{eq:primal_standard_dual_partitioned_combined}) are feasible,
    % can we (always?) achieve that equality in Eq.(\ref{eq:weak_duality_lemma}),
    % e.g.,
    % can the two problems (always?) have the same optimal objective?
    in which case the two problems have the equal optimal objective?
\end{itemize}

TODO



% IIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIIII
\clearpage
\vspace{30pt}
\section{Benders Decomposition}

% ----------------------------
\subsection{To decompose the problem: a bi-level viewpoint}

It may be helpful to consider the Benders decomposition (BD) algorithm as a bi-level nested loop, where
the outer layer loop aims at optimizing some part of the set of decision variables, while
the inner layer loop aims at optimizing the remaining part according to a given (partial) solution from the outer layer.
% ----
In the context of BD,
the outer layer is called a master problem (MP), while the inner is called a sub-problem (SP).
% ----


In this section,
the "part of variables" for outer and inner layer (i.e., the MP and the SP) are denoted by $\mathbf{\color{red} x}$ and $\mathbf{\color{red} y}$ respectively.


For a given MILP (or even more generalized ?) model
\begin{equation}
    \begin{aligned}
        \label{eq:benders_total_problem}
        \text{Minimize} \qquad &
            f_1(  \mathbf{\color{red} x}  ) + f_2(  \mathbf{\color{red} x}  ,  \mathbf{\color{red} y}  )
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                (  \mathbf{\color{red} x}  ,  \mathbf{\color{red} y}  ) \in S
                \\
                \mathbf{\color{red} x}  \in  D_x
                \\
                \mathbf{\color{red} y}  \in  D_y
            \end{cases}
    \end{aligned}
\end{equation}
where $S$ defines the feasibility space (of decision variables $\mathbf{\color{red} x}$ and $\mathbf{\color{red} y}$ ) limited by the constraints,
we can decompose it into a master problem (MP) as Eq.(\ref{eq:benders_outer_problem}) and a sub-problem (SP) as Eq.(\ref{eq:benders_inner_problem}).
% \begin{itemize}
%     \item  The mast
% \end{itemize}
\begin{equation}
    \begin{aligned}
        \label{eq:benders_outer_problem}
        \text{MP:} \qquad &
        \\
        \text{Minimize} \qquad &
            f_1(  \mathbf{\color{red} x}  ) + {\color{red} q}
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                (  \mathbf{\color{red} x}  ,  {\color{red} q}  ) \in S'
                \\
                \mathbf{\color{red} x}  \in  D_x
            \end{cases}
    \end{aligned}
\end{equation}
\begin{equation}
    \begin{aligned}
        \label{eq:benders_inner_problem}
        \text{SP with given} \quad \mathbf{\color{red} x} = \bar{\mathbf{x}_k} \quad & \text{at the} \quad k \text{-th outer iteration:} \qquad
        \\
        \text{Minimize} \qquad &
            f_2(  \bar{\mathbf{x}_k}  ,  \mathbf{\color{red} y}  )
        \\
        \text{s.t.} \qquad &
            \begin{cases}
                (  \bar{\mathbf{x}_k}  ,  \mathbf{\color{red} y}  ) \in S
                \\
                \mathbf{\color{red} y}  \in  D_y
            \end{cases}
    \end{aligned}
\end{equation}
where an additional assistant variable ${\color{red} q}$ is introduced into the master problem,
to embed the "information" about the partial objective from the sub-problem.
These "information" will be implemented in the newly defined feasibility space $S'$
by some techniques (which are the core difficulties of Benders decomposition methods, and will be explained in later sections).


% It may be helpful to consider this procedure as a bi-level nested loop, where
% % the MP corresponds to the outer layer and optimize some part of the variables, and
% % the SP
% the outer layer loop aims at optimizing some part of the set of decision variables (corresponding to the MP), i.e., $\mathbf{\color{red} x}$, while
% the inner layer loop aims at optimizing the remaining part (corresponding to the SP), i.e., $\mathbf{\color{red} y}$, for a value of $\mathbf{\color{red} x}$ given by the outer layer.


% ----------------------------
\subsection{How the two layers interact}


In many bi-level meta-heuristics,
the inner layer is responsible to optimize the sub-problem,
% so that the outer layer can evaluate the partial solution it is focusing on.
providing \textit{clue} for the outer layer to evaluate the partial solution it is focusing on.
% ----
However, the results from the inner layer can also serve as other roles.
% ----
In BD, the results from the inner layer are used to generate constraints (named "cuts") for the outer layer MP.



% ----
Note that,
for a model that already completely expresses a real-world application,
we can still add "redundant" constraints,
and hopefully they may reduce the search space of variables.
These additional constraints are referred to as "speed-up" constraints in some literatures \cite{0148_0227_202012}.



% ----
Constraints can be added before starting optimization.
However, it is also possible to dynamically add constraints during optimization.  % if they cannot be obtained in advance.
There are several motivations for dynamically adding constraints, including:
\begin{itemize}
    \item  The constraints cannot be obtained in advance (before starting optimization).
        For example, BD generates new constraints with the help of computational results from the inner layer.
    \item  There are too many constraints, which may not all be necessary to be added in advance.
        For example, the MILP model proposed by Dantzig et al in 1954 \cite{milp_tsp_1954_DFJ}
        for Traveling Salesman Problem (TSP) with $|V|$ locations has $O(2^{|V|})$ constraints for avoiding sub-tours.
    \item  \dots
\end{itemize}
Fortunately, some MILP solvers support adding constraints in various ways.



% ----
The procedure of BD can be regarded as
dynamically adding speed-up constraints to the master problem
according to information found by the inner layer.
% Specifically, the $(  \mathbf{\color{red} x}  ,  {\color{red} q}  ) \in S'$ in Eq.(\ref{eq:benders_outer_problem}) is dynamically changed,
Specifically, the feasibility space $ S'$ in Eq.(\ref{eq:benders_outer_problem}) is dynamically changed,
embedded with more and more information
from the inner layer results.
% as the iterations increase.

So, how is the information expressed? How does the generated constraints look like?


% ----------------------------
\subsection{Techniques to generate constraints for MP}

Given an outer-layer partial solution $\mathbf{\color{red} x} = \bar{\mathbf{x}_k}$,
the inner layer has returned a (possibly approximately) optimal solution $\mathbf{\color{red} y} = \mathbf{y}^*_k$,
with the corresponding objective value $f_2(  \bar{\mathbf{x}_k}  ,  \mathbf{y}^*_k  )$,
of the SP.
So what is the form of the generated speed-up constraints for MP according to $\mathbf{y}^*_k$ and $f_2(  \bar{\mathbf{x}_k}  ,  \mathbf{y}^*_k  )$?


% ----------------------------
% \subsubsection{A straightforward example}

Let's first look at a simple example.
% We can add a constraint
The constraint
\begin{equation}
    \begin{aligned}
        % \label{eq:}
        {\color{red} q}
        \begin{cases}
            = f_2(  \bar{\mathbf{x}_k}  ,  \mathbf{y}^*_k  ),  &  \mathbf{\color{red} x} =    \bar{\mathbf{x}_k}, \\
            \text{(unconstrained)}                         ,  &  \mathbf{\color{red} x} \neq \bar{\mathbf{x}_k}, \\
        \end{cases}
    \end{aligned}
\end{equation}
provides precise objective for MP when $\mathbf{\color{red} x} = \bar{\mathbf{x}_k}$, and otherwise does nothing.
%
%
This successfully embeds the information from inner-layer result into the outer-layer MP model.
However, the result of the model is useless with this kind of constraints --
At later iterations, the $\mathbf{\color{red} x}$ will be assigned to some value not yet mentioned by any of these constraints,
so the ${\color{red} q}$ can happily escape from all of these constraints and get a value of $-\infty$,
resulting the objective function being minimized to $( - \infty + f_1(  \mathbf{\color{red} x}  ) )$.
% Unless all the
% ----
There is one exception, i.e., if all possible values of $\mathbf{\color{red} x}$ are enumerated by outer layer, solved by inner layer, and contribute a constraint.
However, enumerating all feasible solutions is computationally impossible in most applications. (Otherwise we do not need to research on optimization methods!)


% ----------------------------
\subsubsection{for linear-programming-style SP}


% ----------------------------
\subsubsection{for more general SP}


% ----------------------------
\subsubsection{No-good cuts for more general SP}


\begin{equation}
    \begin{aligned}
        % \label{eq:}
    \end{aligned}
\end{equation}






\end{document}

